import uuid
import logging
from typing import List
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from datetime import datetime, timedelta

from app.core.database import get_db
from app.db.assistant import assistant_config
from app.db.diary import diary
from app.db.goal import goal
from app.db.schedule import schedule
from app.db.entertainment import favorite
from app.models.chat import ChatMessage
from app.models.assistant import AssistantConfig
from app.schemas.chat import (
    ChatMessage, ChatMessageCreate, ChatMessageResponse, ChatRequest, ChatResponse
)
from app.schemas.assistant import (
    AssistantConfigCreate, AssistantConfigUpdate, AssistantConfigResponse
)
from app.services.openai_service import openai_service
from app.utils.dependencies import get_current_active_user
from app.models.user import User

# é…ç½®æ—¥å¿—è®°å½•åˆ°æ–‡ä»¶
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_vendor_debug.log', encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

logger = logging.getLogger(__name__)

router = APIRouter()


async def get_knowledge_context(db: Session, user_id: int, user_message: str) -> str:
    """è·å–ç”¨æˆ·çš„çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    try:
        context_parts = []
        
        # 1. è·å–æœ€è¿‘çš„æ—¥è®°æ¡ç›®ï¼ˆå‡å°‘æ•°é‡å’Œé•¿åº¦ï¼‰
        recent_diaries = diary.get_multi_by_user(db, user_id=user_id, skip=0, limit=3)
        if recent_diaries:
            diary_context = "æœ€è¿‘çš„æ—¥è®°è®°å½•ï¼š\n"
            for entry in recent_diaries:
                diary_context += f"- {entry.created_at.strftime('%Y-%m-%d')}: {entry.title}\n"
                diary_context += f"  å†…å®¹: {entry.content[:100]}...\n"  # å‡å°‘å†…å®¹é•¿åº¦
            context_parts.append(diary_context)
        
        # 2. è·å–æ´»è·ƒçš„ç›®æ ‡ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        active_goals = goal.get_active_by_user(db, user_id=user_id)
        if active_goals:
            goals_context = "å½“å‰æ´»è·ƒç›®æ ‡ï¼š\n"
            for goal_item in active_goals[:3]:  # åªå–å‰3ä¸ªç›®æ ‡
                progress = (goal_item.current_value / goal_item.target_value * 100) if goal_item.target_value else 0
                goals_context += f"- {goal_item.title} (è¿›åº¦: {progress:.1f}%)\n"
                if goal_item.description:
                    goals_context += f"  æè¿°: {goal_item.description[:50]}...\n"  # å‡å°‘æè¿°é•¿åº¦
            context_parts.append(goals_context)
        
        # 3. è·å–ä»Šæ—¥å’Œå³å°†åˆ°æ¥çš„æ—¥ç¨‹ï¼ˆå‡å°‘æ•°é‡ï¼‰
        today_schedules = schedule.get_today_by_user(db, user_id=user_id)
        upcoming_schedules = schedule.get_upcoming_by_user(db, user_id=user_id, days=3)  # å‡å°‘åˆ°3å¤©
        
        if today_schedules or upcoming_schedules:
            schedule_context = "æ—¥ç¨‹å®‰æ’ï¼š\n"
            
            if today_schedules:
                schedule_context += "ä»Šæ—¥æ—¥ç¨‹ï¼š\n"
                for sched in today_schedules[:3]:  # åªå–å‰3ä¸ª
                    schedule_context += f"- {sched.start_time.strftime('%H:%M')}: {sched.title}\n"
                    if sched.description:
                        schedule_context += f"  è¯¦æƒ…: {sched.description[:50]}...\n"  # å‡å°‘è¯¦æƒ…é•¿åº¦
            
            if upcoming_schedules:
                schedule_context += "æœªæ¥3å¤©æ—¥ç¨‹ï¼š\n"
                for sched in upcoming_schedules[:3]:  # åªå–å‰3ä¸ª
                    schedule_context += f"- {sched.start_time.strftime('%m-%d %H:%M')}: {sched.title}\n"
            
            context_parts.append(schedule_context)
        
        # 4. è·å–å¨±ä¹æ”¶è—ï¼ˆå‡å°‘æ•°é‡ï¼‰
        user_favorites = favorite.get_multi_by_user(db, user_id=user_id, skip=0, limit=5)
        if user_favorites:
            entertainment_context = "å¨±ä¹æ”¶è—ï¼š\n"
            for fav in user_favorites:
                if fav.entertainment:
                    entertainment_context += f"- {fav.entertainment.title} ({fav.entertainment.type})\n"
                    if fav.rating:
                        entertainment_context += f"  è¯„åˆ†: {fav.rating}/5\n"
                    if fav.notes:
                        entertainment_context += f"  ç¬”è®°: {fav.notes[:50]}...\n"  # å‡å°‘ç¬”è®°é•¿åº¦
            context_parts.append(entertainment_context)
        
        # 5. è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼ˆç®€åŒ–ï¼‰
        user_info = db.query(User).filter(User.id == user_id).first()
        if user_info:
            user_context = "ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼š\n"
            user_context += f"- ç”¨æˆ·å: {user_info.username}\n"
            if user_info.full_name:
                user_context += f"- å§“å: {user_info.full_name}\n"
            # ç§»é™¤ä¸ªäººç®€ä»‹ä»¥å‡å°‘æ•°æ®é‡
            context_parts.append(user_context)
        
        # åˆå¹¶æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œå¹¶é™åˆ¶æ€»é•¿åº¦
        if context_parts:
            full_context = "\n".join(context_parts)
            # é™åˆ¶æ€»ä¸Šä¸‹æ–‡é•¿åº¦åœ¨1000å­—ç¬¦ä»¥å†…
            if len(full_context) > 1000:
                full_context = full_context[:1000] + "...\n[ä¸Šä¸‹æ–‡å·²æˆªæ–­]"
            return full_context
        else:
            return ""
            
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
        return ""


@router.get("/debug")
async def debug_route():
    """è°ƒè¯•è·¯ç”± - ç¡®è®¤AIè·¯ç”±æ­£å¸¸å·¥ä½œ"""
    print("ğŸ” [DEBUG] AIè·¯ç”±è¢«è®¿é—®!")
    return {"message": "AIè·¯ç”±å·¥ä½œæ­£å¸¸", "status": "ok"}


@router.post("/chat", response_model=ChatResponse)
async def chat_with_ai(
    chat_request: ChatRequest,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """ä¸AIèŠå¤©"""
    # è·å–åŠ©æ‰‹é…ç½®
    assistant_cfg = None
    if chat_request.assistant_config_id:
        assistant_cfg = assistant_config.get(db, chat_request.assistant_config_id)
        if not assistant_cfg or assistant_cfg.user_id != current_user.id:
            raise HTTPException(status_code=404, detail="Assistant config not found")
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®
        assistant_cfg = assistant_config.get_default_by_user(db, user_id=current_user.id)
        if not assistant_cfg:
            raise HTTPException(status_code=404, detail="No default assistant config found")

    # ç”Ÿæˆæˆ–ä½¿ç”¨ç°æœ‰ä¼šè¯ID
    session_id = chat_request.session_id or str(uuid.uuid4())

    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ - ä½¿ç”¨æ•°æ®åº“æ¨¡å‹è€Œä¸æ˜¯Pydantic Schema
    from datetime import datetime
    from app.models.chat import ChatMessage as ChatMessageModel
    
    user_message = ChatMessageModel(
        user_id=current_user.id,
        session_id=session_id,
        assistant_config_id=assistant_cfg.id,
        role="user",
        content=chat_request.message,
        tokens_used=0,  # ç”¨æˆ·æ¶ˆæ¯ä¸æ¶ˆè€—tokens
        model=None,  # ç”¨æˆ·æ¶ˆæ¯ä¸éœ€è¦æ¨¡å‹
        created_at=datetime.utcnow()  # æ˜¾å¼è®¾ç½®åˆ›å»ºæ—¶é—´
    )
    db.add(user_message)
    db.flush()  # ç¡®ä¿ç”¨æˆ·æ¶ˆæ¯è·å¾—ID

    # æ„å»ºå¯¹è¯å†å²
    chat_history = db.query(ChatMessageModel).filter(
        ChatMessageModel.session_id == session_id
    ).order_by(ChatMessageModel.created_at).limit(20).all()

    messages = []
    
    # æ„å»ºç³»ç»Ÿæç¤ºï¼ŒåŒ…å«çŸ¥è¯†åº“ä¿¡æ¯
    system_prompt = assistant_cfg.prompt or "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ã€‚"
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨çŸ¥è¯†åº“å¹¶è·å–ç›¸å…³çŸ¥è¯†
    if chat_request.use_knowledge_base is not False:  # é»˜è®¤å¯ç”¨çŸ¥è¯†åº“
        knowledge_context = await get_knowledge_context(db, current_user.id, chat_request.message)
        if knowledge_context:
            system_prompt += f"\n\nä»¥ä¸‹æ˜¯ç”¨æˆ·çš„ä¸ªäººæ•°æ®ï¼Œè¯·æ ¹æ®è¿™äº›ä¿¡æ¯æä¾›æ›´ä¸ªæ€§åŒ–çš„å›ç­”ï¼š\n\n{knowledge_context}"
    
    messages.append({"role": "system", "content": system_prompt})

    for msg in chat_history:
        messages.append({"role": msg.role, "content": msg.content})

    try:
        # è·å–ç”¨æˆ·é…ç½®çš„APIä¿¡æ¯
        api_config = assistant_cfg.config or {}
        vendor_url = api_config.get("vendor_url")
        api_key = api_config.get("api_key")
        
        # ğŸ” è¯¦ç»†çš„æœåŠ¡å•†é…ç½®è°ƒè¯•ä¿¡æ¯
        print(f"\nğŸ” [AIèŠå¤©] æœåŠ¡å•†é…ç½®è¯¦æƒ…:")
        print(f"   ğŸ“‹ åŠ©æ‰‹é…ç½®ID: {assistant_cfg.id}")
        print(f"   ğŸ¤– é…ç½®çš„æ¨¡å‹: {assistant_cfg.model}")
        print(f"   ğŸ”— ä¾›åº”å•†URL: {vendor_url}")
        print(f"   ğŸ”‘ APIå¯†é’¥çŠ¶æ€: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        print(f"   ğŸ“ å®Œæ•´APIé…ç½®: {api_config}")
        print(f"   ğŸ‘¤ ç”¨æˆ·ID: {current_user.id}")
        print(f"   ğŸ’¬ ä¼šè¯ID: {session_id}")
        
        logger.info(f"è°ƒè¯•ä¿¡æ¯ - åŠ©æ‰‹é…ç½®ID: {assistant_cfg.id}")
        logger.info(f"è°ƒè¯•ä¿¡æ¯ - é…ç½®çš„æ¨¡å‹: {assistant_cfg.model}")
        logger.info(f"è°ƒè¯•ä¿¡æ¯ - APIé…ç½®: {api_config}")
        logger.info(f"è°ƒè¯•ä¿¡æ¯ - ä¾›åº”å•†URL: {vendor_url}")
        logger.info(f"è°ƒè¯•ä¿¡æ¯ - APIå¯†é’¥: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        
        # åˆ›å»ºä½¿ç”¨ç”¨æˆ·é…ç½®çš„æœåŠ¡å®ä¾‹
        if vendor_url and api_key:
            print(f"   âœ… ä½¿ç”¨è‡ªå®šä¹‰ä¾›åº”å•†: {vendor_url}")
            logger.info(f"è°ƒè¯•ä¿¡æ¯ - ä½¿ç”¨è‡ªå®šä¹‰ä¾›åº”å•†: {vendor_url}")
            ai_service = openai_service.__class__(api_key=api_key, base_url=vendor_url)
        else:
            # å¦‚æœæ²¡æœ‰é…ç½®è‡ªå®šä¹‰APIï¼Œä½¿ç”¨é»˜è®¤æœåŠ¡
            print(f"   âš ï¸  ä½¿ç”¨é»˜è®¤OpenAIæœåŠ¡")
            logger.info(f"è°ƒè¯•ä¿¡æ¯ - ä½¿ç”¨é»˜è®¤OpenAIæœåŠ¡")
            ai_service = openai_service
        
        # è°ƒç”¨AI API
        response = await ai_service.chat_completion(
            messages=messages,
            model=assistant_cfg.model,
            temperature=float(assistant_cfg.temperature),
            max_tokens=assistant_cfg.max_tokens,
            top_p=float(assistant_cfg.top_p),
            frequency_penalty=float(assistant_cfg.frequency_penalty),
            presence_penalty=float(assistant_cfg.presence_penalty)
        )

        ai_content = response["choices"][0]["message"]["content"]
        tokens_used = response["usage"]["total_tokens"]
        model_used = response["model"]

        # ä¿å­˜AIå›å¤ - ä½¿ç”¨æ•°æ®åº“æ¨¡å‹è€Œä¸æ˜¯Pydantic Schema
        ai_message = ChatMessageModel(
            user_id=current_user.id,
            session_id=session_id,
            assistant_config_id=assistant_cfg.id,
            role="assistant",
            content=ai_content,
            tokens_used=tokens_used,
            model=model_used,
            created_at=datetime.utcnow()  # æ˜¾å¼è®¾ç½®åˆ›å»ºæ—¶é—´
        )
        db.add(ai_message)
        db.commit()

        return ChatResponse(
            message=ai_content,
            session_id=session_id,
            tokens_used=tokens_used,
            model=model_used
        )

    except Exception as e:
        db.rollback()
        # ğŸ” è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯è¾“å‡º
        print(f"\nâŒ [AIèŠå¤©] å¼‚å¸¸è¯¦æƒ…:")
        print(f"   ğŸ” é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   ğŸ“ é”™è¯¯æ¶ˆæ¯: {str(e)}")
        print(f"   ğŸ“Š é”™è¯¯è¯¦æƒ…: {repr(e)}")
        print(f"   ğŸ‘¤ ç”¨æˆ·ID: {current_user.id}")
        print(f"   ğŸ’¬ ä¼šè¯ID: {session_id}")
        print(f"   ğŸ¤– åŠ©æ‰‹é…ç½®ID: {assistant_cfg.id}")
        
        logger.error(f"AIèŠå¤©å¼‚å¸¸ - ç±»å‹: {type(e).__name__}, æ¶ˆæ¯: {str(e)}")
        logger.error(f"ç”¨æˆ·ID: {current_user.id}, ä¼šè¯ID: {session_id}, é…ç½®ID: {assistant_cfg.id}")
        
        raise HTTPException(status_code=500, detail=f"AI service error: {str(e)}")


@router.get("/chat/history/{session_id}", response_model=List[ChatMessageResponse])
async def get_chat_history(
    session_id: str,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–èŠå¤©å†å²"""
    from app.models.chat import ChatMessage as ChatMessageModel
    
    messages = db.query(ChatMessageModel).filter(
        ChatMessageModel.session_id == session_id,
        ChatMessageModel.user_id == current_user.id
    ).order_by(ChatMessageModel.created_at).all()
    return messages


@router.get("/chat/sessions", response_model=List[str])
async def get_chat_sessions(
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æ‰€æœ‰ä¼šè¯ID"""
    from app.models.chat import ChatMessage as ChatMessageModel
    
    sessions = db.query(ChatMessageModel.session_id).filter(
        ChatMessageModel.user_id == current_user.id
    ).distinct().all()
    return [session[0] for session in sessions]


@router.post("/test", response_model=dict)
async def test_ai_connection(
    test_config: dict = None,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """æµ‹è¯•AIè¿æ¥"""
    if test_config:
        # ä½¿ç”¨ç”¨æˆ·æä¾›çš„é…ç½®è¿›è¡Œæµ‹è¯•
        vendor_url = test_config.get("vendor_url")
        api_key = test_config.get("api_key")
        model = test_config.get("model", "gpt-3.5-turbo")
        
        # ğŸ” æµ‹è¯•è¿æ¥çš„è¯¦ç»†æœåŠ¡å•†ä¿¡æ¯
        print(f"\nğŸ” [æµ‹è¯•è¿æ¥] ç”¨æˆ·æä¾›çš„é…ç½®:")
        print(f"   ğŸ”— ä¾›åº”å•†URL: {vendor_url}")
        print(f"   ğŸ¤– æ¨¡å‹åç§°: {model}")
        print(f"   ğŸ”‘ APIå¯†é’¥çŠ¶æ€: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        print(f"   ğŸ‘¤ æµ‹è¯•ç”¨æˆ·ID: {current_user.id}")
        
        logger.info(f"æµ‹è¯•è¿æ¥ - ç”¨æˆ·æä¾›çš„é…ç½®URL: {vendor_url}")
        logger.info(f"æµ‹è¯•è¿æ¥ - ç”¨æˆ·æä¾›çš„æ¨¡å‹: {model}")
        logger.info(f"æµ‹è¯•è¿æ¥ - APIå¯†é’¥çŠ¶æ€: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        
        if not vendor_url or not api_key:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: ç¼ºå°‘ä¾›åº”å•†åœ°å€æˆ–API Key")
            return {
                "status": "error",
                "message": "è¯·æä¾›ä¾›åº”å•†åœ°å€å’ŒAPI Key"
            }
        
        # åˆ›å»ºä¸´æ—¶æœåŠ¡å®ä¾‹è¿›è¡Œæµ‹è¯•
        print(f"   ğŸš€ åˆ›å»ºä¸´æ—¶æœåŠ¡å®ä¾‹è¿›è¡Œæµ‹è¯•...")
        temp_service = openai_service.__class__(api_key=api_key, base_url=vendor_url)
        
        try:
            print(f"   ğŸ“¤ å‘é€æµ‹è¯•è¯·æ±‚åˆ°: {vendor_url}")
            test_messages = [
                {"role": "user", "content": "Hello, this is a test message."}
            ]
            response = await temp_service.chat_completion(
                messages=test_messages,
                model=model,
                max_tokens=10
            )
            print(f"   âœ… æµ‹è¯•æˆåŠŸ! å“åº”æ¨¡å‹: {response.get('model')}")
            print(f"   ğŸ“Š Tokenä½¿ç”¨: {response.get('usage')}")
            return {
                "status": "success",
                "message": "APIè¿æ¥æˆåŠŸ",
                "model": response.get("model"),
                "usage": response.get("usage")
            }
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            print(f"   ğŸ” é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   ğŸ“Š é”™è¯¯è¯¦æƒ…: {repr(e)}")
            logger.error(f"æµ‹è¯•è¿æ¥å¤±è´¥ - ç±»å‹: {type(e).__name__}, æ¶ˆæ¯: {str(e)}")
            return {
                "status": "error",
                "message": f"APIè¿æ¥å¤±è´¥: {str(e)}"
            }
    else:
        # ä½¿ç”¨ç”¨æˆ·çš„é»˜è®¤é…ç½®è¿›è¡Œæµ‹è¯•
        try:
            # è·å–ç”¨æˆ·çš„é»˜è®¤åŠ©æ‰‹é…ç½®
            default_config = assistant_config.get_default_by_user(db, user_id=current_user.id)
            if default_config:
                # ğŸ” é»˜è®¤é…ç½®æµ‹è¯•çš„è¯¦ç»†æœåŠ¡å•†ä¿¡æ¯
                print(f"\nğŸ” [æµ‹è¯•è¿æ¥] ä½¿ç”¨é»˜è®¤é…ç½®:")
                print(f"   ğŸ“‹ é»˜è®¤é…ç½®ID: {default_config.id}")
                print(f"   ğŸ¤– é»˜è®¤é…ç½®æ¨¡å‹: {default_config.model}")
                print(f"   ğŸ‘¤ ç”¨æˆ·ID: {current_user.id}")
                
                logger.info(f"æµ‹è¯•è¿æ¥ - é»˜è®¤é…ç½®ID: {default_config.id}")
                logger.info(f"æµ‹è¯•è¿æ¥ - é»˜è®¤é…ç½®æ¨¡å‹: {default_config.model}")
                
                # è·å–ç”¨æˆ·é…ç½®çš„APIä¿¡æ¯
                api_config = default_config.config or {}
                vendor_url = api_config.get("vendor_url")
                api_key = api_config.get("api_key")
                
                print(f"   ğŸ”— ä¾›åº”å•†URL: {vendor_url}")
                print(f"   ğŸ”‘ APIå¯†é’¥çŠ¶æ€: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
                print(f"   ğŸ“ å®Œæ•´APIé…ç½®: {api_config}")
                
                logger.info(f"æµ‹è¯•è¿æ¥ - APIé…ç½®: {api_config}")
                logger.info(f"æµ‹è¯•è¿æ¥ - ä¾›åº”å•†URL: {vendor_url}")
                logger.info(f"æµ‹è¯•è¿æ¥ - APIå¯†é’¥: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
                
                if vendor_url and api_key:
                    # ä½¿ç”¨ç”¨æˆ·é…ç½®çš„æœåŠ¡å®ä¾‹
                    print(f"   âœ… ä½¿ç”¨è‡ªå®šä¹‰ä¾›åº”å•†è¿›è¡Œæµ‹è¯•: {vendor_url}")
                    logger.info(f"æµ‹è¯•è¿æ¥ - ä½¿ç”¨è‡ªå®šä¹‰ä¾›åº”å•†: {vendor_url}")
                    ai_service = openai_service.__class__(api_key=api_key, base_url=vendor_url)
                    
                    print(f"   ğŸ“¤ å‘é€æµ‹è¯•è¯·æ±‚...")
                    test_messages = [
                        {"role": "user", "content": "Hello, this is a test message."}
                    ]
                    response = await ai_service.chat_completion(
                        messages=test_messages,
                        model=default_config.model,
                        max_tokens=10
                    )
                    print(f"   âœ… é»˜è®¤é…ç½®æµ‹è¯•æˆåŠŸ! å“åº”æ¨¡å‹: {response.get('model')}")
                    print(f"   ğŸ“Š Tokenä½¿ç”¨: {response.get('usage')}")
                    return {
                        "status": "success",
                        "message": "APIè¿æ¥æˆåŠŸ",
                        "model": response.get("model"),
                        "usage": response.get("usage")
                    }
                else:
                    return {
                        "status": "error",
                        "message": "é»˜è®¤é…ç½®ä¸­ç¼ºå°‘ä¾›åº”å•†åœ°å€æˆ–APIå¯†é’¥ï¼Œè¯·åœ¨è®¾ç½®ä¸­å®Œå–„é…ç½®"
                    }
            else:
                return {
                    "status": "error",
                    "message": "æœªæ‰¾åˆ°é»˜è®¤é…ç½®ï¼Œè¯·åœ¨è®¾ç½®ä¸­åˆ›å»ºå¹¶è®¾ä¸ºé»˜è®¤é…ç½®"
                }
        except Exception as e:
            print(f"\nâŒ [æµ‹è¯•è¿æ¥] é»˜è®¤é…ç½®å¼‚å¸¸:")
            print(f"   ğŸ” é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   ğŸ“ é”™è¯¯æ¶ˆæ¯: {str(e)}")
            print(f"   ğŸ“Š é”™è¯¯è¯¦æƒ…: {repr(e)}")
            print(f"   ğŸ‘¤ ç”¨æˆ·ID: {current_user.id}")
            
            logger.error(f"é»˜è®¤é…ç½®æµ‹è¯•å¼‚å¸¸ - ç±»å‹: {type(e).__name__}, æ¶ˆæ¯: {str(e)}")
            logger.error(f"ç”¨æˆ·ID: {current_user.id}")
            
            return {
                "status": "error",
                "message": f"æµ‹è¯•è¿æ¥å¤±è´¥: {str(e)}"
            }


@router.get("/models", response_model=List[str])
async def get_available_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return await openai_service.get_models()


# åŠ©æ‰‹é…ç½®ç›¸å…³ç«¯ç‚¹
@router.post("/configs", response_model=AssistantConfigResponse)
async def create_assistant_config(
    config: AssistantConfigCreate,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """åˆ›å»ºåŠ©æ‰‹é…ç½®"""
    try:
        # å°†APIé…ç½®ä¿¡æ¯å­˜å‚¨åœ¨configå­—æ®µä¸­
        config_data = config.dict()
        
        # å¦‚æœæ²¡æœ‰è®¾ç½®promptï¼Œä½¿ç”¨é»˜è®¤prompt
        if not config_data.get("prompt"):
            config_data["prompt"] = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ã€‚"
        
        assistant_cfg = assistant_config.create_with_user(db, obj_in=config, user_id=current_user.id)
        return assistant_cfg
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=400, detail=f"åˆ›å»ºé…ç½®å¤±è´¥: {str(e)}")


@router.get("/configs", response_model=List[AssistantConfigResponse])
async def get_assistant_configs(
    skip: int = 0,
    limit: int = 100,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–ç”¨æˆ·çš„åŠ©æ‰‹é…ç½®åˆ—è¡¨"""
    configs = assistant_config.get_multi_by_user(db, user_id=current_user.id, skip=skip, limit=limit)
    return configs


@router.get("/configs/{config_id}", response_model=AssistantConfigResponse)
async def get_assistant_config(
    config_id: int,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–ç‰¹å®šçš„åŠ©æ‰‹é…ç½®"""
    config = assistant_config.get(db, id=config_id)
    if not config or config.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Assistant config not found")
    return config


@router.put("/configs/{config_id}", response_model=AssistantConfigResponse)
async def update_assistant_config(
    config_id: int,
    config_update: AssistantConfigUpdate,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """æ›´æ–°åŠ©æ‰‹é…ç½®"""
    config = assistant_config.get(db, id=config_id)
    if not config or config.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Assistant config not found")
    
    updated_config = assistant_config.update_with_user(db, db_obj=config, obj_in=config_update)
    return updated_config


@router.delete("/configs/{config_id}")
async def delete_assistant_config(
    config_id: int,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤åŠ©æ‰‹é…ç½®"""
    config = assistant_config.get(db, id=config_id)
    if not config or config.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Assistant config not found")
    
    assistant_config.remove(db, id=config_id)
    return {"message": "Assistant config deleted successfully"}


@router.post("/configs/{config_id}/set-default")
async def set_default_config(
    config_id: int,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è®¾ç½®é»˜è®¤åŠ©æ‰‹é…ç½®"""
    config = assistant_config.get(db, id=config_id)
    if not config or config.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Assistant config not found")
    
    # å…ˆå–æ¶ˆæ‰€æœ‰é»˜è®¤é…ç½®
    db.query(AssistantConfig).filter(
        AssistantConfig.user_id == current_user.id
    ).update({"is_default": False})
    
    # è®¾ç½®æ–°çš„é»˜è®¤é…ç½®
    config.is_default = True
    db.commit()
    
    return {"message": "Default config set successfully"}


@router.post("/generate-study-plan", response_model=dict)
async def generate_study_plan(
    request: dict,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """AIç”Ÿæˆå­¦ä¹ è®¡åˆ’"""
    try:
        # è·å–ç”¨æˆ·çš„é»˜è®¤åŠ©æ‰‹é…ç½®
        assistant_cfg = assistant_config.get_default_by_user(db, user_id=current_user.id)
        if not assistant_cfg:
            raise HTTPException(status_code=404, detail="No default assistant config found")
        
        # è·å–ç”¨æˆ·é…ç½®çš„APIä¿¡æ¯
        api_config = assistant_cfg.config or {}
        vendor_url = api_config.get("vendor_url")
        api_key = api_config.get("api_key")
        
        # ğŸ” å­¦ä¹ è®¡åˆ’ç”Ÿæˆçš„è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        print(f"\nğŸ” [å­¦ä¹ è®¡åˆ’ç”Ÿæˆ] å¼€å§‹ç”Ÿæˆå­¦ä¹ è®¡åˆ’:")
        print(f"   ğŸ‘¤ ç”¨æˆ·ID: {current_user.id}")
        print(f"   ğŸ“‹ åŠ©æ‰‹é…ç½®ID: {assistant_cfg.id}")
        print(f"   ğŸ¤– é…ç½®çš„æ¨¡å‹: {assistant_cfg.model}")
        print(f"   ğŸ”— ä¾›åº”å•†URL: {vendor_url}")
        print(f"   ğŸ”‘ APIå¯†é’¥çŠ¶æ€: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        
        logger.info(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆ - ç”¨æˆ·ID: {current_user.id}")
        logger.info(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆ - åŠ©æ‰‹é…ç½®ID: {assistant_cfg.id}")
        logger.info(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆ - æ¨¡å‹: {assistant_cfg.model}")
        
        # åˆ›å»ºä½¿ç”¨ç”¨æˆ·é…ç½®çš„æœåŠ¡å®ä¾‹
        if vendor_url and api_key:
            print(f"   âœ… ä½¿ç”¨è‡ªå®šä¹‰ä¾›åº”å•†: {vendor_url}")
            logger.info(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆ - ä½¿ç”¨è‡ªå®šä¹‰ä¾›åº”å•†: {vendor_url}")
            ai_service = openai_service.__class__(api_key=api_key, base_url=vendor_url)
        else:
            print(f"   âš ï¸  ä½¿ç”¨é»˜è®¤OpenAIæœåŠ¡")
            logger.info(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆ - ä½¿ç”¨é»˜è®¤OpenAIæœåŠ¡")
            ai_service = openai_service
        
        # è·å–ç”¨æˆ·éœ€æ±‚
        user_requirement = request.get("prompt", "è¯·ä¸ºæˆ‘ç”Ÿæˆä¸€ä¸ªé€šç”¨çš„å­¦ä¹ è®¡åˆ’ï¼Œé€‚åˆåˆå­¦è€…å…¥é—¨")
        
        # è·å–ç”¨æˆ·çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼Œæä¾›ä¸ªæ€§åŒ–ä¿¡æ¯
        knowledge_context = await get_knowledge_context(db, current_user.id, user_requirement)
        
        # æ„å»ºä¼˜åŒ–çš„å­¦ä¹ è®¡åˆ’ç”Ÿæˆç³»ç»Ÿæç¤ºï¼ˆæ›´ç®€æ´ï¼‰
        system_prompt = """å­¦ä¹ è®¡åˆ’ç”ŸæˆåŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”ŸæˆJSONæ ¼å¼å­¦ä¹ è®¡åˆ’ã€‚

æ ¼å¼è¦æ±‚ï¼š
{
  "title": "ç®€çŸ­æ ‡é¢˜",
  "priority": "High/Medium/Low",
  "tasks": [
    {"title": "ä»»åŠ¡1", "duration": "30m"},
    {"title": "ä»»åŠ¡2", "duration": "1h"}
  ]
}

è¦æ±‚ï¼š3-5ä¸ªä»»åŠ¡ï¼Œæ€»æ—¶é•¿2-6å°æ—¶ï¼Œå¾ªåºæ¸è¿›ã€‚åªè¿”å›JSONï¼Œæ— å…¶ä»–æ–‡å­—ã€‚"""

        # æ„å»ºæ¶ˆæ¯ï¼ŒåŒ…å«çŸ¥è¯†åº“ä¸Šä¸‹æ–‡
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # å¦‚æœæœ‰çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
        if knowledge_context:
            user_content = f"ç”¨æˆ·éœ€æ±‚ï¼š{user_requirement}\n\nç”¨æˆ·èƒŒæ™¯ä¿¡æ¯ï¼š\n{knowledge_context}"
        else:
            user_content = f"ç”¨æˆ·éœ€æ±‚ï¼š{user_requirement}"
        
        messages.append({"role": "user", "content": user_content})
        
        print(f"   ğŸ“¤ å‘é€å­¦ä¹ è®¡åˆ’ç”Ÿæˆè¯·æ±‚...")
        print(f"   ğŸ“ ç”¨æˆ·éœ€æ±‚: {user_requirement}")
        print(f"   ğŸ“š çŸ¥è¯†åº“ä¸Šä¸‹æ–‡: {'æœ‰' if knowledge_context else 'æ— '}")
        
        # è°ƒç”¨AI APIï¼Œä¼˜åŒ–å‚æ•°è®¾ç½®
        response = await ai_service.chat_completion(
            messages=messages,
            model=assistant_cfg.model,
            temperature=0.3,  # ç¨å¾®æé«˜æ¸©åº¦ï¼ŒåŠ å¿«ç”Ÿæˆé€Ÿåº¦
            max_tokens=500,   # å‡å°‘max_tokensï¼Œå› ä¸ºå­¦ä¹ è®¡åˆ’ä¸éœ€è¦å¤ªé•¿
            top_p=0.9,
            frequency_penalty=0.0,
            presence_penalty=0.0,
            timeout=120  # å‡å°‘è¶…æ—¶æ—¶é—´åˆ°2åˆ†é’Ÿï¼Œå› ä¸ºä¼˜åŒ–ååº”è¯¥æ›´å¿«
        )
        
        ai_content = response["choices"][0]["message"]["content"].strip()
        tokens_used = response["usage"]["total_tokens"]
        model_used = response["model"]
        
        print(f"   âœ… AIç”ŸæˆæˆåŠŸ!")
        print(f"   ğŸ“ ç”Ÿæˆå†…å®¹: {ai_content[:200]}...")
        print(f"   ğŸ“Š Tokenä½¿ç”¨: {tokens_used}")
        print(f"   ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_used}")
        
        logger.info(f"å­¦ä¹ è®¡åˆ’ç”ŸæˆæˆåŠŸ - Tokenä½¿ç”¨: {tokens_used}")
        logger.info(f"å­¦ä¹ è®¡åˆ’ç”ŸæˆæˆåŠŸ - æ¨¡å‹: {model_used}")
        
        # å°è¯•è§£æJSONï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›åŸå§‹å†…å®¹
        try:
            # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
            if ai_content.startswith("```json"):
                ai_content = ai_content.replace("```json", "").replace("```", "").strip()
            
            parsed_plan = eval(ai_content)  # ä½¿ç”¨evalè€Œä¸æ˜¯json.parseï¼Œå› ä¸ºAIå¯èƒ½è¿”å›å•å¼•å·
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if not isinstance(parsed_plan, dict):
                raise ValueError("è¿”å›çš„ä¸æ˜¯å­—å…¸æ ¼å¼")
            
            if "title" not in parsed_plan or "priority" not in parsed_plan or "tasks" not in parsed_plan:
                raise ValueError("ç¼ºå°‘å¿…è¦å­—æ®µ")
            
            if not isinstance(parsed_plan["tasks"], list):
                raise ValueError("taskså­—æ®µä¸æ˜¯åˆ—è¡¨")
            
            # éªŒè¯æ¯ä¸ªä»»åŠ¡
            for task in parsed_plan["tasks"]:
                if not isinstance(task, dict) or "title" not in task or "duration" not in task:
                    raise ValueError("ä»»åŠ¡æ ¼å¼ä¸æ­£ç¡®")
            
            print(f"   âœ… JSONè§£ææˆåŠŸï¼Œæ ¼å¼æ­£ç¡®")
            
            return {
                "status": "success",
                "data": parsed_plan,
                "tokens_used": tokens_used,
                "model": model_used
            }
            
        except Exception as parse_error:
            print(f"   âš ï¸  JSONè§£æå¤±è´¥: {str(parse_error)}")
            print(f"   ğŸ“ åŸå§‹å†…å®¹: {ai_content}")
            logger.error(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆ - JSONè§£æå¤±è´¥: {str(parse_error)}")
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹è®©å‰ç«¯å¤„ç†
            return {
                "status": "parse_error",
                "raw_content": ai_content,
                "tokens_used": tokens_used,
                "model": model_used,
                "error": f"JSONè§£æå¤±è´¥: {str(parse_error)}"
            }
        
    except Exception as e:
        # ğŸ” è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯è¾“å‡º
        print(f"\nâŒ [å­¦ä¹ è®¡åˆ’ç”Ÿæˆ] å¼‚å¸¸è¯¦æƒ…:")
        print(f"   ğŸ” é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   ğŸ“ é”™è¯¯æ¶ˆæ¯: {str(e)}")
        print(f"   ğŸ“Š é”™è¯¯è¯¦æƒ…: {repr(e)}")
        print(f"   ğŸ‘¤ ç”¨æˆ·ID: {current_user.id}")
        
        logger.error(f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆå¼‚å¸¸ - ç±»å‹: {type(e).__name__}, æ¶ˆæ¯: {str(e)}")
        logger.error(f"ç”¨æˆ·ID: {current_user.id}")
        
        raise HTTPException(status_code=500, detail=f"å­¦ä¹ è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")